{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import praw\n",
    "import queue\n",
    "import requests\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBREDDITS = [\"earthporn\", \"spaceporn\"]\n",
    "MAX_IMG = 100\n",
    "MAX_WORKERS=6\n",
    "ACCEPTABLE_EXTENSIONS = [\"jpg\", \"png\"]\n",
    "reddit = praw.Reddit(\"cs4243\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = queue.Queue()\n",
    "def get_image(url, filename) :\n",
    "    req = requests.get(url, stream=True)\n",
    "    with open(filename, 'wb') as f:\n",
    "        for chunk in req.iter_content(1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "def worker():\n",
    "    while True:\n",
    "        subr, id, url = q.get()\n",
    "        get_image(url, f\"./{subr.lower()}/{id}.jpg\")\n",
    "        q.task_done()\n",
    "\n",
    "all_threads = [threading.Thread(target=worker) for _ in range(MAX_WORKERS)]\n",
    "for t in all_threads:\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sourcing 10/200\n",
      "Sourcing 20/200\n",
      "Sourcing 30/200\n",
      "Sourcing 40/200\n",
      "Sourcing 50/200\n",
      "Sourcing 60/200\n",
      "Sourcing 70/200\n",
      "Sourcing 80/200\n",
      "Sourcing 90/200\n",
      "Sourcing 100/200\n",
      "Sourcing 110/200\n",
      "Sourcing 120/200\n",
      "Sourcing 130/200\n",
      "Sourcing 140/200\n",
      "Sourcing 150/200\n",
      "Sourcing 160/200\n",
      "Sourcing 170/200\n",
      "Sourcing 180/200\n",
      "Sourcing 190/200\n",
      "Sourcing 200/200\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "unixnow = int(datetime.datetime.timestamp(now))\n",
    "datafile = open(f\"crawl_{now.month:02}{now.day:02}.csv\", 'w')\n",
    "datafile.write(\"CS4243_crawler data\\n\")\n",
    "datafile.write(\"subreddits\\n\" + '\\n'.join(SUBREDDITS) + '\\n\\n')\n",
    "for sr in SUBREDDITS:\n",
    "    # os.makedirs(f\"./{sr}_{now.month:02}{now.day:02}\", exist_ok=True)\n",
    "    os.makedirs(f\"./{sr.lower()}\", exist_ok=True)\n",
    "\n",
    "sr_count = {}\n",
    "for sr in SUBREDDITS:\n",
    "    sr_count[sr.lower()] = 0\n",
    "all_count = 0\n",
    "all_limit = len(SUBREDDITS)*MAX_IMG\n",
    "datafile.write(\"SUBREDDIT,ID,SCORE,URL,\\n\")\n",
    "for submission in reddit.subreddit(\"+\".join(SUBREDDITS)).new(limit=None):\n",
    "    if (unixnow - submission.created_utc) > 604800:\n",
    "        srname = submission.subreddit.display_name.lower()\n",
    "        if sr_count[srname] >= MAX_IMG:\n",
    "            continue\n",
    "        if submission.url[-3:] not in ACCEPTABLE_EXTENSIONS:\n",
    "            continue\n",
    "        datafile.write(f\"{srname},{submission.id},{submission.score},{submission.url}\\n\")\n",
    "        q.put((srname, submission.id, submission.url))\n",
    "        sr_count[srname] += 1\n",
    "        all_count += 1\n",
    "\n",
    "        if all_count % 10 == 0:\n",
    "            datafile.flush()\n",
    "            print(f\"Sourcing {all_count}/{all_limit}\")\n",
    "            # break\n",
    "        if all_count == all_limit:\n",
    "            break\n",
    "q.join()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5df0192bec759d1f7484f54f673824e28388fbedcfd4d53bba5ff9ed1739130e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('reddit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
